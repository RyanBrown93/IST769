{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec49ce1-8ba0-4b80-b6ef-8da3a04a1fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e093c115-341d-4ba1-a466-cddb8690fb9c;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/3.0.1/mongo-spark-connector_2.12-3.0.1.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb.spark#mongo-spark-connector_2.12;3.0.1!mongo-spark-connector_2.12.jar (67ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.0.5/mongodb-driver-sync-4.0.5.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-sync;4.0.5!mongodb-driver-sync.jar (19ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson/4.0.5/bson-4.0.5.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson;4.0.5!bson.jar (46ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.0.5/mongodb-driver-core-4.0.5.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-core;4.0.5!mongodb-driver-core.jar (116ms)\n",
      ":: resolution report :: resolve 1788ms :: artifacts dl 257ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   4   |   4   |   0   ||   4   |   4   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e093c115-341d-4ba1-a466-cddb8690fb9c\n",
      "\tconfs: [default]\n",
      "\t4 artifacts copied, 0 already retrieved (2728kB/21ms)\n",
      "24/11/10 18:44:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb://admin:mongopw@mongo:27017/demo.feedback?authSource=admin\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "mongo_uri = \"mongodb://admin:mongopw@mongo:27017/demo.feedback?authSource=admin\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-psyspark') \\\n",
    "        .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "        .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "        .config(\"spark.jars.packages\",\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(mongo_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd03ba3b-4cfb-4959-b33a-84f3355e41cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///home/jovyan/datasets/json-samples/US-Senators.json\n"
     ]
    }
   ],
   "source": [
    "source_file = \"file:///home/jovyan/datasets/json-samples/US-Senators.json\"\n",
    "df = spark.read.json(source_file)\n",
    "\n",
    "df.write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"labf\").option(\"collection\",\"senators\").save()\n",
    "print(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4fb7204-470f-4fd2-8197-fd72610dc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///home/jovyan/datasets/netflix-canceled-2021/*.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "source_file = \"file:///home/jovyan/datasets/netflix-canceled-2021/*.json\"\n",
    "\n",
    "nfcan = spark.read.option(\"multiline\", True).json(source_file)\n",
    "\n",
    "nfcan.write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"labf\").option(\"collection\",\"nfcan\").save()\n",
    "print(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fa649e6-8b6e-4b1b-a39b-b912c310317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+------+------+----------+-------+\n",
      "|      showname|     name|season|number|   airdate|average|\n",
      "+--------------+---------+------+------+----------+-------+\n",
      "|Peaky Blinders|Episode 1|     1|     1|2013-09-12|    8.3|\n",
      "|Peaky Blinders|Episode 2|     1|     2|2013-09-19|    8.4|\n",
      "|Peaky Blinders|Episode 3|     1|     3|2013-09-26|    8.4|\n",
      "|Peaky Blinders|Episode 4|     1|     4|2013-10-03|    8.4|\n",
      "|Peaky Blinders|Episode 5|     1|     5|2013-10-10|    8.6|\n",
      "|Peaky Blinders|Episode 6|     1|     6|2013-10-17|    8.8|\n",
      "|Peaky Blinders|Episode 1|     2|     1|2014-10-02|    7.8|\n",
      "|Peaky Blinders|Episode 2|     2|     2|2014-10-09|    8.1|\n",
      "|Peaky Blinders|Episode 3|     2|     3|2014-10-16|    8.2|\n",
      "|Peaky Blinders|Episode 4|     2|     4|2014-10-23|    8.2|\n",
      "|Peaky Blinders|Episode 5|     2|     5|2014-10-30|    8.2|\n",
      "|Peaky Blinders|Episode 6|     2|     6|2014-11-06|    8.7|\n",
      "|Peaky Blinders|Episode 1|     3|     1|2016-05-05|    8.3|\n",
      "|Peaky Blinders|Episode 2|     3|     2|2016-05-12|    8.5|\n",
      "|Peaky Blinders|Episode 3|     3|     3|2016-05-19|    8.7|\n",
      "|Peaky Blinders|Episode 4|     3|     4|2016-05-26|    8.5|\n",
      "|Peaky Blinders|Episode 5|     3|     5|2016-06-02|    8.4|\n",
      "|Peaky Blinders|Episode 6|     3|     6|2016-06-09|    9.0|\n",
      "|Peaky Blinders|The Noose|     4|     1|2017-11-15|    8.5|\n",
      "|Peaky Blinders| Heathens|     4|     2|2017-11-22|    8.5|\n",
      "+--------------+---------+------+------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "tmp = nfcan.select(col(\"name\").alias(\"showname\"),\n",
    "                   explode(\"_embedded.episodes\").alias(\"episode\")\n",
    "                  )\n",
    "eps = tmp.select(\"showname\", \"episode.name\", \"episode.season\", \"episode.number\", \"episode.airdate\", \"episode.rating.average\")\n",
    "eps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "977a16ed-391b-40b3-a9b9-b07e8043f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps.createOrReplaceTempView(\"eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f277a3d-0929-43f1-b814-8d67a88760e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- showname: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- season: long (nullable = true)\n",
      " |-- number: long (nullable = true)\n",
      " |-- airdate: string (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+------+------+----------+-------+----------+\n",
      "|    showname|            name|season|number|   airdate|average|low_rating|\n",
      "+------------+----------------+------+------+----------+-------+----------+\n",
      "|Mr. Iglesias|  Generation Why|     2|     4|2020-06-17|    4.0|       4.0|\n",
      "|Mr. Iglesias|Food for Thought|     2|     5|2020-06-17|    4.5|       4.0|\n",
      "+------------+----------------+------+------+----------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eps.printSchema()\n",
    "query = '''\n",
    "WITH Source AS\n",
    "(\n",
    "    SELECT showname, name, season, number, airdate, average, \n",
    "        MIN(average) OVER (PARTITION BY showname, season) AS low_rating\n",
    "    FROM eps\n",
    ")\n",
    "SELECT * FROM Source WHERE average < 5\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8a3682d-91c3-42c1-a175-34f6154fd879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "shows = nfcan.select(\"name\").distinct().sort(\"name\").toPandas()[\"name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f147b5e-ca65-4525-9355-48822c6b9229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<H1>Netflix shows cancelled in 2021</H1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b669e8b86d9c4042b17bb497dc6ad9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='show', options=('#blackAF', 'Bonding', 'Country Comfort', 'Cowboy â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "from ipywidgets import interact\n",
    "\n",
    "display(HTML(\"<H1>Netflix shows cancelled in 2021</H1>\"))\n",
    "\n",
    "@interact(show = shows)\n",
    "def comboChanged(show):\n",
    "    theShow = nfcan.select(\"name\", \"summary\", \"image.medium\", \"status\", \"rating.average\")\\\n",
    "        .where(nfcan.name == show).toPandas().iloc[0]\n",
    "    display(HTML(f\"<H3>{theShow['name']}</H3>\"))\n",
    "    display(Image(url = theShow[\"medium\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a03f0b0f-9d7f-4a7e-b407-5ccc2f9e0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps.createOrReplaceTempView(\"eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd7717f3-b799-4900-9957-3b1fa4780eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- showname: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- season: long (nullable = true)\n",
      " |-- number: long (nullable = true)\n",
      " |-- airdate: string (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      "\n",
      "+-----------------+------+--------------+--------------------+------+\n",
      "|         showname|season|episode_number|        episode_name|rating|\n",
      "+-----------------+------+--------------+--------------------+------+\n",
      "|   Peaky Blinders|     5|             5|           The Shock|   8.3|\n",
      "| The Last Kingdom|     4|             1|           Episode 1|   8.6|\n",
      "| The Last Kingdom|     4|             6|           Episode 6|   8.6|\n",
      "|         The Crew|     1|            10|No One Likes You....|   5.8|\n",
      "|   Peaky Blinders|     1|             1|           Episode 1|   8.3|\n",
      "|     Mr. Iglesias|     2|             4|      Generation Why|   4.0|\n",
      "|Kim's Convenience|     1|             1|        Gay Discount|   8.0|\n",
      "|Kim's Convenience|     1|             4|     Frank & Nayoung|   8.0|\n",
      "|Kim's Convenience|     4|             4|   Happy Ummaversary|   7.0|\n",
      "|Kim's Convenience|     4|             6|          Soccer Dad|   7.0|\n",
      "|Kim's Convenience|     4|            12|        Knife Strife|   7.0|\n",
      "|     Mr. Iglesias|     3|             2|         Good Things|   7.3|\n",
      "|     Mr. Iglesias|     3|             3|   Playing Favorites|   7.3|\n",
      "|     Mr. Iglesias|     3|             5|       The Big Dance|   7.3|\n",
      "|   Peaky Blinders|     4|             3|           Blackbird|   8.0|\n",
      "|         #blackAF|     1|             1|  because of slavery|   5.3|\n",
      "|         #blackAF|     1|             2|because of slaver...|   5.3|\n",
      "|      On My Block|     1|             4|        Chapter Four|   5.0|\n",
      "|      On My Block|     3|             8|Chapter Twenty-Eight|   7.5|\n",
      "|   Peaky Blinders|     3|             1|           Episode 1|   8.3|\n",
      "+-----------------+------+--------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------------+------+--------------+--------------------+------+\n",
      "|         showname|season|episode_number|        episode_name|rating|\n",
      "+-----------------+------+--------------+--------------------+------+\n",
      "|   Peaky Blinders|     5|             5|           The Shock|   8.3|\n",
      "| The Last Kingdom|     4|             1|           Episode 1|   8.6|\n",
      "| The Last Kingdom|     4|             6|           Episode 6|   8.6|\n",
      "|         The Crew|     1|            10|No One Likes You....|   5.8|\n",
      "|   Peaky Blinders|     1|             1|           Episode 1|   8.3|\n",
      "|     Mr. Iglesias|     2|             4|      Generation Why|   4.0|\n",
      "|Kim's Convenience|     1|             1|        Gay Discount|   8.0|\n",
      "|Kim's Convenience|     1|             4|     Frank & Nayoung|   8.0|\n",
      "|Kim's Convenience|     4|             4|   Happy Ummaversary|   7.0|\n",
      "|Kim's Convenience|     4|             6|          Soccer Dad|   7.0|\n",
      "|Kim's Convenience|     4|            12|        Knife Strife|   7.0|\n",
      "|     Mr. Iglesias|     3|             2|         Good Things|   7.3|\n",
      "|     Mr. Iglesias|     3|             3|   Playing Favorites|   7.3|\n",
      "|     Mr. Iglesias|     3|             5|       The Big Dance|   7.3|\n",
      "|   Peaky Blinders|     4|             3|           Blackbird|   8.0|\n",
      "|         #blackAF|     1|             1|  because of slavery|   5.3|\n",
      "|         #blackAF|     1|             2|because of slaver...|   5.3|\n",
      "|      On My Block|     1|             4|        Chapter Four|   5.0|\n",
      "|      On My Block|     3|             8|Chapter Twenty-Eight|   7.5|\n",
      "|   Peaky Blinders|     3|             1|           Episode 1|   8.3|\n",
      "+-----------------+------+--------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eps.printSchema()\n",
    "query = '''\n",
    "WITH Source AS (\n",
    "    SELECT \n",
    "        showname,\n",
    "        name, \n",
    "        season, \n",
    "        number, \n",
    "        airdate, \n",
    "        average,\n",
    "        MIN(average) OVER (PARTITION BY showname, season) AS low_rating\n",
    "    FROM eps\n",
    ")\n",
    "SELECT \n",
    "    showname, \n",
    "    season, \n",
    "    number AS episode_number, \n",
    "    name AS episode_name, \n",
    "    average AS rating\n",
    "FROM Source\n",
    "WHERE average = low_rating\n",
    "'''\n",
    "\n",
    "# Execute the query\n",
    "result = spark.sql(query)\n",
    "\n",
    "# Show the result\n",
    "result.show()\n",
    "\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49f6e705-27f7-4289-983c-b07b91f97217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- showname: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- season: long (nullable = true)\n",
      " |-- number: long (nullable = true)\n",
      " |-- airdate: string (nullable = true)\n",
      " |-- average: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eps.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c47993-3433-4201-b93d-c4297c9fbf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
